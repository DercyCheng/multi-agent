# Multi-Agent Platform Configuration
# This is the unified configuration file for all services

# Server Configuration
server:
  api_gateway:
    port: 8080
    host: "0.0.0.0"
    mode: "production" # development, production
    graceful_timeout: "30s"
    read_timeout: "10s"
    write_timeout: "10s"
    max_header_bytes: 8192

  orchestrator:
    port: 8081
    host: "0.0.0.0"
    grpc_port: 50052
    health_port: 8081
    graceful_timeout: "30s"

  agent_core:
    port: 8082
    host: "0.0.0.0"
    grpc_port: 50051
    health_port: 8082

  llm_service:
    port: 8000
    host: "0.0.0.0"
    workers: 4
    reload: false

# Database Configuration
database:
  postgres:
    host: "postgres"
    port: 5432
    database: "multiagent"
    username: "postgres"
    password: "${POSTGRES_PASSWORD:-password}"
    sslmode: "disable"
    max_open_conns: 25
    max_idle_conns: 5
    conn_max_lifetime: "300s"

  redis:
    host: "redis"
    port: 6379
    database: 0
    password: "${REDIS_PASSWORD:-}"
    max_retries: 3
    pool_size: 10
    min_idle_conns: 1
    dial_timeout: "5s"
    read_timeout: "3s"
    write_timeout: "3s"

  qdrant:
    host: "qdrant"
    port: 6333
    grpc_port: 6334
    api_key: "${QDRANT_API_KEY:-}"
    timeout: "30s"
    collections:
      memories:
        vector_size: 1536
        distance: "Cosine"
      context:
        vector_size: 1536
        distance: "Cosine"
      tools:
        vector_size: 1536
        distance: "Cosine"

# Authentication & Authorization
auth:
  enabled: true
  skip_auth: false
  jwt_secret: "${JWT_SECRET:-your-super-secret-jwt-key-change-in-production}"
  access_token_expiry: "30m"
  refresh_token_expiry: "168h" # 7 days
  api_key_rate_limit: 1000
  password_hash_cost: 12

  # Rate limiting
  rate_limit:
    enabled: true
    requests_per_minute: 60
    burst: 10
    cleanup_interval: "1m"

# LLM Service Configuration
llm:
  providers:
    openai:
      enabled: true
      api_key: "${OPENAI_API_KEY}"
      base_url: "https://api.openai.com/v1"
      timeout: "60s"
      max_retries: 3

    anthropic:
      enabled: true
      api_key: "${ANTHROPIC_API_KEY}"
      base_url: "https://api.anthropic.com"
      timeout: "60s"
      max_retries: 3

    google:
      enabled: false
      api_key: "${GOOGLE_API_KEY}"
      timeout: "60s"

  model_tiers:
    small:
      allocation: 50
      models:
        - provider: "openai"
          model: "gpt-4o-mini"
          priority: 1
        - provider: "anthropic"
          model: "claude-3-5-haiku-20241022"
          priority: 2

    medium:
      allocation: 40
      models:
        - provider: "openai"
          model: "gpt-4o"
          priority: 1
        - provider: "anthropic"
          model: "claude-3-5-sonnet-20241022"
          priority: 2

    large:
      allocation: 10
      models:
        - provider: "openai"
          model: "gpt-4o"
          priority: 1
        - provider: "anthropic"
          model: "claude-3-5-sonnet-20241022"
          priority: 2

  # Cost Controls
  cost_controls:
    max_cost_per_request: 0.10
    daily_budget_usd: 100.0
    alert_threshold_percent: 80

  # Prompt Caching
  prompt_cache:
    enabled: true
    similarity_threshold: 0.95
    ttl_seconds: 3600
    max_cache_size: 1000

# Agent Core Configuration
agent_core:
  enforcement:
    timeout_seconds: 30
    max_tokens: 100000
    rate_limit_per_key: 1000
    circuit_breaker:
      max_failures: 5
      timeout_seconds: 60
      max_requests: 10

  wasi_sandbox:
    memory_limit_mb: 256
    cpu_timeout_seconds: 30
    filesystem_read_only: true
    network_access: false

  memory_pool:
    initial_size_mb: 64
    max_size_mb: 512
    gc_threshold: 0.8

  tools:
    registry_size: 1000
    cache_ttl_seconds: 300
    discovery_timeout_seconds: 10

# Orchestrator Configuration
orchestrator:
  temporal:
    host: "temporal"
    port: 7233
    namespace: "multi-agent"
    task_queue: "orchestrator-tasks"

  workflow:
    max_parallel_agents: 5
    default_timeout: "300s"
    retry_attempts: 3

  budget:
    default_token_limit: 10000
    daily_reset: true
    grace_period_percent: 10

  circuit_breakers:
    redis:
      max_requests: 5
      timeout: "60s"
      max_failures: 5
    database:
      max_requests: 3
      timeout: "60s"
      max_failures: 3
    agent_core:
      max_requests: 10
      timeout: "30s"
      max_failures: 3

# MCP Tools Configuration
mcp_tools:
  registry_token: "${MCP_REGISTER_TOKEN:-}"
  default_timeout: "30s"
  max_tools_per_agent: 10

  # Pre-configured tools
  weather_api:
    enabled: false
    url: "https://api.weather.com/mcp"
    func_name: "get_weather"
    description: "Get weather information for a city"
    category: "weather"
    cost_per_use: 0.001
    parameters:
      - name: "city"
        type: "string"
        required: true
        description: "City name"
    headers:
      X-API-Key: "${WEATHER_API_KEY:-}"

# Monitoring & Observability
monitoring:
  prometheus:
    enabled: true
    port: 9090
    path: "/metrics"
    scrape_interval: "15s"

  jaeger:
    enabled: true
    endpoint: "http://jaeger:14268/api/traces"
    service_name: "multi-agent"
    sampler_type: "const"
    sampler_param: 1

  logging:
    level: "info" # debug, info, warn, error
    format: "json" # json, text
    output: "stdout" # stdout, file
    file_path: "/var/log/multi-agent.log"
    max_size_mb: 100
    max_files: 3
    max_age_days: 7

# Security Configuration
security:
  opa:
    enabled: true
    policy_path: "/policies"
    bundle_url: "${OPA_BUNDLE_URL:-}"
    decision_timeout: "1s"

  cors:
    enabled: true
    allow_origins: ["*"]
    allow_methods: ["GET", "POST", "PUT", "DELETE", "OPTIONS"]
    allow_headers: ["*"]
    expose_headers: ["*"]
    allow_credentials: true
    max_age: 3600

  tls:
    enabled: false
    cert_file: "${TLS_CERT_FILE:-}"
    key_file: "${TLS_KEY_FILE:-}"
    ca_file: "${TLS_CA_FILE:-}"

# Feature Flags
features:
  multi_tenant: true
  blockchain_integration: false
  advanced_analytics: true
  experimental_features: false
  debug_mode: false

# Environment Specific Overrides
environment: "${ENVIRONMENT:-development}" # development, staging, production

# Development specific settings
development:
  hot_reload: true
  verbose_logging: true
  disable_auth: false
  mock_llm_responses: false

# Production specific settings
production:
  hot_reload: false
  verbose_logging: false
  force_https: true
  enable_profiling: false
